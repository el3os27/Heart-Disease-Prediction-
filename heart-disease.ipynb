{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5171140,"sourceType":"datasetVersion","datasetId":3005565},{"sourceId":5176185,"sourceType":"datasetVersion","datasetId":3008928}],"dockerImageVersionId":30476,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nimport h5py\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.metrics import MeanIoU\nimport matplotlib.pyplot as plt\n\n# Set random seed for reproducibility\nnp.random.seed(42)\ntf.random.set_seed(42)\n\n# Define image parameters\nimg_width, img_height = 384, 384  # Matches your dataset dimensions\ninput_shape = (img_width, img_height, 1)  # Grayscale images\nbatch_size = 8\nepochs = 50\n\n# Load CAMUS dataset from HDF5 file\ndef load_camus_data(hdf5_path):\n    with h5py.File(hdf5_path, 'r') as f:\n        # Load 2CH and 4CH views\n        train_2ch_frames = np.array(f['train 2ch frames'])\n        train_2ch_masks = np.array(f['train 2ch masks'])\n        train_4ch_frames = np.array(f['train 4ch frames'])\n        train_4ch_masks = np.array(f['train 4ch masks'])\n        \n        # Combine all frames and masks\n        all_frames = np.concatenate([train_2ch_frames, train_4ch_frames], axis=0)\n        all_masks = np.concatenate([train_2ch_masks, train_4ch_masks], axis=0)\n        \n        # Shuffle the data\n        indices = np.arange(len(all_frames))\n        np.random.shuffle(indices)\n        all_frames = all_frames[indices]\n        all_masks = all_masks[indices]\n        \n        # Split into train/val/test (70%/15%/15%)\n        train_size = int(0.7 * len(all_frames))\n        val_size = int(0.15 * len(all_frames))\n        \n        train_images = all_frames[:train_size]\n        train_masks = all_masks[:train_size]\n        \n        val_images = all_frames[train_size:train_size+val_size]\n        val_masks = all_masks[train_size:train_size+val_size]\n        \n        test_images = all_frames[train_size+val_size:]\n        test_masks = all_masks[train_size+val_size:]\n        \n    return (train_images, train_masks), (val_images, val_masks), (test_images, test_masks)\n\n# Load the data\ntry:\n    hdf5_path = \"../input/camus-dataset/image_dataset.hdf5\"\n    print(f\"Loading data from: {hdf5_path}\")\n    (train_images, train_masks), (val_images, val_masks), (test_images, test_masks) = load_camus_data(hdf5_path)\n    \n    print(\"\\nData loaded successfully!\")\n    print(f\"Training images shape: {train_images.shape}\")\n    print(f\"Training masks shape: {train_masks.shape}\")\n    print(f\"Validation images shape: {val_images.shape}\")\n    print(f\"Test images shape: {test_images.shape}\")\n    \nexcept Exception as e:\n    print(f\"\\nError loading data: {e}\")\n    raise\n\n# Data augmentation function\ndef augment_data(images, masks):\n    # Convert masks to float32 for augmentation\n    masks = masks.astype('float32')\n    \n    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n        rotation_range=10,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        shear_range=0.1,\n        zoom_range=0.1,\n        horizontal_flip=True,\n        fill_mode='nearest')\n    \n    seed = 42\n    image_generator = datagen.flow(images, seed=seed, batch_size=batch_size)\n    mask_generator = datagen.flow(masks, seed=seed, batch_size=batch_size)\n    \n    while True:\n        yield (next(image_generator), next(mask_generator))\n\n# Normalize images to [0,1] and masks to binary (0 or 1)\ntrain_images = train_images.astype('float32') / 255.0\ntrain_masks = (train_masks > 0).astype('float32')  # Convert to binary masks\n\nval_images = val_images.astype('float32') / 255.0\nval_masks = (val_masks > 0).astype('float32')\n\ntest_images = test_images.astype('float32') / 255.0\ntest_masks = (test_masks > 0).astype('float32')\n\n# Create data generators\ntrain_generator = augment_data(train_images, train_masks)\n\n# Simple generator for validation (no augmentation)\ndef val_data_generator(images, masks):\n    while True:\n        for i in range(0, len(images), batch_size):\n            yield (images[i:i+batch_size], masks[i:i+batch_size])\n\nval_generator = val_data_generator(val_images, val_masks)\n\n# Build U-Net model\ndef build_unet(input_shape):\n    inputs = Input(input_shape)\n    \n    # Downsample path\n    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n    \n    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    \n    # Bottleneck\n    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n    \n    # Upsample path\n    up4 = Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(conv3)\n    up4 = concatenate([up4, conv2])\n    conv4 = Conv2D(128, 3, activation='relu', padding='same')(up4)\n    conv4 = Conv2D(128, 3, activation='relu', padding='same')(conv4)\n    \n    up5 = Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv4)\n    up5 = concatenate([up5, conv1])\n    conv5 = Conv2D(64, 3, activation='relu', padding='same')(up5)\n    conv5 = Conv2D(64, 3, activation='relu', padding='same')(conv5)\n    \n    outputs = Conv2D(1, 1, activation='sigmoid')(conv5)\n    \n    return Model(inputs=[inputs], outputs=[outputs])\n\nmodel = build_unet(input_shape)\nmodel.compile(optimizer=Adam(learning_rate=1e-4),\n              loss='binary_crossentropy',\n              metrics=['accuracy', MeanIoU(num_classes=2)])\n\nmodel.summary()\n\n# Callbacks\ncallbacks = [\n    EarlyStopping(patience=10, verbose=1),\n    ModelCheckpoint('camus_best_model.h5', verbose=1, save_best_only=True)\n]\n\n# Calculate steps per epoch\nsteps_per_epoch = len(train_images) // batch_size\nvalidation_steps = len(val_images) // batch_size\n\n# Train the model\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=steps_per_epoch,\n    epochs=epochs,\n    validation_data=val_generator,\n    validation_steps=validation_steps,\n    callbacks=callbacks)\n\n# Evaluation on test set\ntest_results = model.evaluate(test_images, test_masks, batch_size=batch_size)\nprint(f\"Test Loss: {test_results[0]}, Test Accuracy: {test_results[1]}, Test IoU: {test_results[2]}\")\n\n# Save the final model\nmodel.save('camus_echo_segmentation_final.h5')\n\nprint(\"Training completed and model saved!\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-04-16T23:05:01.071127Z","iopub.execute_input":"2025-04-16T23:05:01.071632Z","iopub.status.idle":"2025-04-17T00:36:11.570808Z","shell.execute_reply.started":"2025-04-16T23:05:01.071604Z","shell.execute_reply":"2025-04-17T00:36:11.569922Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Loading data from: ../input/camus-dataset/image_dataset.hdf5\n\nData loaded successfully!\nTraining images shape: (1260, 384, 384, 1)\nTraining masks shape: (1260, 384, 384, 1)\nValidation images shape: (270, 384, 384, 1)\nTest images shape: (270, 384, 384, 1)\nModel: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 384, 384, 1  0           []                               \n                                )]                                                                \n                                                                                                  \n conv2d (Conv2D)                (None, 384, 384, 64  640         ['input_1[0][0]']                \n                                )                                                                 \n                                                                                                  \n conv2d_1 (Conv2D)              (None, 384, 384, 64  36928       ['conv2d[0][0]']                 \n                                )                                                                 \n                                                                                                  \n max_pooling2d (MaxPooling2D)   (None, 192, 192, 64  0           ['conv2d_1[0][0]']               \n                                )                                                                 \n                                                                                                  \n conv2d_2 (Conv2D)              (None, 192, 192, 12  73856       ['max_pooling2d[0][0]']          \n                                8)                                                                \n                                                                                                  \n conv2d_3 (Conv2D)              (None, 192, 192, 12  147584      ['conv2d_2[0][0]']               \n                                8)                                                                \n                                                                                                  \n max_pooling2d_1 (MaxPooling2D)  (None, 96, 96, 128)  0          ['conv2d_3[0][0]']               \n                                                                                                  \n conv2d_4 (Conv2D)              (None, 96, 96, 256)  295168      ['max_pooling2d_1[0][0]']        \n                                                                                                  \n conv2d_5 (Conv2D)              (None, 96, 96, 256)  590080      ['conv2d_4[0][0]']               \n                                                                                                  \n conv2d_transpose (Conv2DTransp  (None, 192, 192, 12  131200     ['conv2d_5[0][0]']               \n ose)                           8)                                                                \n                                                                                                  \n concatenate (Concatenate)      (None, 192, 192, 25  0           ['conv2d_transpose[0][0]',       \n                                6)                                'conv2d_3[0][0]']               \n                                                                                                  \n conv2d_6 (Conv2D)              (None, 192, 192, 12  295040      ['concatenate[0][0]']            \n                                8)                                                                \n                                                                                                  \n conv2d_7 (Conv2D)              (None, 192, 192, 12  147584      ['conv2d_6[0][0]']               \n                                8)                                                                \n                                                                                                  \n conv2d_transpose_1 (Conv2DTran  (None, 384, 384, 64  32832      ['conv2d_7[0][0]']               \n spose)                         )                                                                 \n                                                                                                  \n concatenate_1 (Concatenate)    (None, 384, 384, 12  0           ['conv2d_transpose_1[0][0]',     \n                                8)                                'conv2d_1[0][0]']               \n                                                                                                  \n conv2d_8 (Conv2D)              (None, 384, 384, 64  73792       ['concatenate_1[0][0]']          \n                                )                                                                 \n                                                                                                  \n conv2d_9 (Conv2D)              (None, 384, 384, 64  36928       ['conv2d_8[0][0]']               \n                                )                                                                 \n                                                                                                  \n conv2d_10 (Conv2D)             (None, 384, 384, 1)  65          ['conv2d_9[0][0]']               \n                                                                                                  \n==================================================================================================\nTotal params: 1,861,697\nTrainable params: 1,861,697\nNon-trainable params: 0\n__________________________________________________________________________________________________\nEpoch 1/50\n157/157 [==============================] - ETA: 0s - loss: 0.5856 - accuracy: 0.7523 - mean_io_u: 0.3801\nEpoch 1: val_loss improved from inf to 0.55462, saving model to camus_best_model.h5\n157/157 [==============================] - 120s 628ms/step - loss: 0.5856 - accuracy: 0.7523 - mean_io_u: 0.3801 - val_loss: 0.5546 - val_accuracy: 0.7561 - val_mean_io_u: 0.3780\nEpoch 2/50\n157/157 [==============================] - ETA: 0s - loss: 0.4784 - accuracy: 0.7547 - mean_io_u: 0.3806\nEpoch 2: val_loss improved from 0.55462 to 0.39943, saving model to camus_best_model.h5\n157/157 [==============================] - 117s 691ms/step - loss: 0.4784 - accuracy: 0.7547 - mean_io_u: 0.3806 - val_loss: 0.3994 - val_accuracy: 0.7561 - val_mean_io_u: 0.3780\nEpoch 3/50\n157/157 [==============================] - ETA: 0s - loss: 0.3982 - accuracy: 0.7546 - mean_io_u: 0.3806\nEpoch 3: val_loss improved from 0.39943 to 0.39447, saving model to camus_best_model.h5\n157/157 [==============================] - 108s 689ms/step - loss: 0.3982 - accuracy: 0.7546 - mean_io_u: 0.3806 - val_loss: 0.3945 - val_accuracy: 0.7561 - val_mean_io_u: 0.3780\nEpoch 4/50\n157/157 [==============================] - ETA: 0s - loss: 0.3911 - accuracy: 0.7578 - mean_io_u: 0.3805\nEpoch 4: val_loss improved from 0.39447 to 0.39135, saving model to camus_best_model.h5\n157/157 [==============================] - 108s 689ms/step - loss: 0.3911 - accuracy: 0.7578 - mean_io_u: 0.3805 - val_loss: 0.3913 - val_accuracy: 0.7561 - val_mean_io_u: 0.3780\nEpoch 5/50\n157/157 [==============================] - ETA: 0s - loss: 0.3854 - accuracy: 0.7646 - mean_io_u: 0.3805\nEpoch 5: val_loss did not improve from 0.39135\n157/157 [==============================] - 108s 690ms/step - loss: 0.3854 - accuracy: 0.7646 - mean_io_u: 0.3805 - val_loss: 0.3951 - val_accuracy: 0.7578 - val_mean_io_u: 0.3780\nEpoch 6/50\n157/157 [==============================] - ETA: 0s - loss: 0.3802 - accuracy: 0.7713 - mean_io_u: 0.3805\nEpoch 6: val_loss improved from 0.39135 to 0.37924, saving model to camus_best_model.h5\n157/157 [==============================] - 108s 690ms/step - loss: 0.3802 - accuracy: 0.7713 - mean_io_u: 0.3805 - val_loss: 0.3792 - val_accuracy: 0.7853 - val_mean_io_u: 0.3780\nEpoch 7/50\n157/157 [==============================] - ETA: 0s - loss: 0.3780 - accuracy: 0.7831 - mean_io_u: 0.3799\nEpoch 7: val_loss improved from 0.37924 to 0.37410, saving model to camus_best_model.h5\n157/157 [==============================] - 108s 690ms/step - loss: 0.3780 - accuracy: 0.7831 - mean_io_u: 0.3799 - val_loss: 0.3741 - val_accuracy: 0.7871 - val_mean_io_u: 0.3780\nEpoch 8/50\n157/157 [==============================] - ETA: 0s - loss: 0.3716 - accuracy: 0.7870 - mean_io_u: 0.3801\nEpoch 8: val_loss did not improve from 0.37410\n157/157 [==============================] - 108s 690ms/step - loss: 0.3716 - accuracy: 0.7870 - mean_io_u: 0.3801 - val_loss: 0.3834 - val_accuracy: 0.7597 - val_mean_io_u: 0.3780\nEpoch 9/50\n157/157 [==============================] - ETA: 0s - loss: 0.3726 - accuracy: 0.7892 - mean_io_u: 0.3798\nEpoch 9: val_loss improved from 0.37410 to 0.36834, saving model to camus_best_model.h5\n157/157 [==============================] - 108s 689ms/step - loss: 0.3726 - accuracy: 0.7892 - mean_io_u: 0.3798 - val_loss: 0.3683 - val_accuracy: 0.7896 - val_mean_io_u: 0.3780\nEpoch 10/50\n157/157 [==============================] - ETA: 0s - loss: 0.3649 - accuracy: 0.7928 - mean_io_u: 0.3801\nEpoch 10: val_loss improved from 0.36834 to 0.36659, saving model to camus_best_model.h5\n157/157 [==============================] - 109s 691ms/step - loss: 0.3649 - accuracy: 0.7928 - mean_io_u: 0.3801 - val_loss: 0.3666 - val_accuracy: 0.7926 - val_mean_io_u: 0.3780\nEpoch 11/50\n157/157 [==============================] - ETA: 0s - loss: 0.3634 - accuracy: 0.7946 - mean_io_u: 0.3801\nEpoch 11: val_loss did not improve from 0.36659\n157/157 [==============================] - 109s 692ms/step - loss: 0.3634 - accuracy: 0.7946 - mean_io_u: 0.3801 - val_loss: 0.3710 - val_accuracy: 0.7890 - val_mean_io_u: 0.3780\nEpoch 12/50\n157/157 [==============================] - ETA: 0s - loss: 0.3620 - accuracy: 0.7946 - mean_io_u: 0.3804\nEpoch 12: val_loss improved from 0.36659 to 0.36114, saving model to camus_best_model.h5\n157/157 [==============================] - 108s 690ms/step - loss: 0.3620 - accuracy: 0.7946 - mean_io_u: 0.3804 - val_loss: 0.3611 - val_accuracy: 0.7969 - val_mean_io_u: 0.3780\nEpoch 13/50\n157/157 [==============================] - ETA: 0s - loss: 0.3614 - accuracy: 0.7975 - mean_io_u: 0.3806\nEpoch 13: val_loss did not improve from 0.36114\n157/157 [==============================] - 109s 692ms/step - loss: 0.3614 - accuracy: 0.7975 - mean_io_u: 0.3806 - val_loss: 0.3653 - val_accuracy: 0.7941 - val_mean_io_u: 0.3780\nEpoch 14/50\n157/157 [==============================] - ETA: 0s - loss: 0.3609 - accuracy: 0.7972 - mean_io_u: 0.3803\nEpoch 14: val_loss improved from 0.36114 to 0.36067, saving model to camus_best_model.h5\n157/157 [==============================] - 109s 692ms/step - loss: 0.3609 - accuracy: 0.7972 - mean_io_u: 0.3803 - val_loss: 0.3607 - val_accuracy: 0.7986 - val_mean_io_u: 0.3780\nEpoch 15/50\n157/157 [==============================] - ETA: 0s - loss: 0.3586 - accuracy: 0.7983 - mean_io_u: 0.3802\nEpoch 15: val_loss did not improve from 0.36067\n157/157 [==============================] - 108s 689ms/step - loss: 0.3586 - accuracy: 0.7983 - mean_io_u: 0.3802 - val_loss: 0.3657 - val_accuracy: 0.7998 - val_mean_io_u: 0.3780\nEpoch 16/50\n157/157 [==============================] - ETA: 0s - loss: 0.3575 - accuracy: 0.7991 - mean_io_u: 0.3803\nEpoch 16: val_loss improved from 0.36067 to 0.35643, saving model to camus_best_model.h5\n157/157 [==============================] - 108s 690ms/step - loss: 0.3575 - accuracy: 0.7991 - mean_io_u: 0.3803 - val_loss: 0.3564 - val_accuracy: 0.8021 - val_mean_io_u: 0.3780\nEpoch 17/50\n157/157 [==============================] - ETA: 0s - loss: 0.3580 - accuracy: 0.7992 - mean_io_u: 0.3790\nEpoch 17: val_loss did not improve from 0.35643\n157/157 [==============================] - 108s 690ms/step - loss: 0.3580 - accuracy: 0.7992 - mean_io_u: 0.3790 - val_loss: 0.3654 - val_accuracy: 0.7846 - val_mean_io_u: 0.3780\nEpoch 18/50\n157/157 [==============================] - ETA: 0s - loss: 0.3554 - accuracy: 0.8015 - mean_io_u: 0.3801\nEpoch 18: val_loss improved from 0.35643 to 0.35516, saving model to camus_best_model.h5\n157/157 [==============================] - 109s 692ms/step - loss: 0.3554 - accuracy: 0.8015 - mean_io_u: 0.3801 - val_loss: 0.3552 - val_accuracy: 0.8013 - val_mean_io_u: 0.3780\nEpoch 19/50\n157/157 [==============================] - ETA: 0s - loss: 0.3535 - accuracy: 0.8040 - mean_io_u: 0.3810\nEpoch 19: val_loss improved from 0.35516 to 0.35272, saving model to camus_best_model.h5\n157/157 [==============================] - 108s 691ms/step - loss: 0.3535 - accuracy: 0.8040 - mean_io_u: 0.3810 - val_loss: 0.3527 - val_accuracy: 0.8049 - val_mean_io_u: 0.3780\nEpoch 20/50\n157/157 [==============================] - ETA: 0s - loss: 0.3504 - accuracy: 0.8066 - mean_io_u: 0.3799\nEpoch 20: val_loss improved from 0.35272 to 0.34802, saving model to camus_best_model.h5\n157/157 [==============================] - 108s 690ms/step - loss: 0.3504 - accuracy: 0.8066 - mean_io_u: 0.3799 - val_loss: 0.3480 - val_accuracy: 0.8110 - val_mean_io_u: 0.3780\nEpoch 21/50\n157/157 [==============================] - ETA: 0s - loss: 0.3495 - accuracy: 0.8090 - mean_io_u: 0.3808\nEpoch 21: val_loss did not improve from 0.34802\n157/157 [==============================] - 108s 690ms/step - loss: 0.3495 - accuracy: 0.8090 - mean_io_u: 0.3808 - val_loss: 0.3542 - val_accuracy: 0.8071 - val_mean_io_u: 0.3780\nEpoch 22/50\n157/157 [==============================] - ETA: 0s - loss: 0.3472 - accuracy: 0.8101 - mean_io_u: 0.3803\nEpoch 22: val_loss did not improve from 0.34802\n157/157 [==============================] - 108s 690ms/step - loss: 0.3472 - accuracy: 0.8101 - mean_io_u: 0.3803 - val_loss: 0.3483 - val_accuracy: 0.8094 - val_mean_io_u: 0.3780\nEpoch 23/50\n157/157 [==============================] - ETA: 0s - loss: 0.3473 - accuracy: 0.8112 - mean_io_u: 0.3802\nEpoch 23: val_loss improved from 0.34802 to 0.34371, saving model to camus_best_model.h5\n157/157 [==============================] - 109s 692ms/step - loss: 0.3473 - accuracy: 0.8112 - mean_io_u: 0.3802 - val_loss: 0.3437 - val_accuracy: 0.8153 - val_mean_io_u: 0.3780\nEpoch 24/50\n157/157 [==============================] - ETA: 0s - loss: 0.3448 - accuracy: 0.8127 - mean_io_u: 0.3809\nEpoch 24: val_loss did not improve from 0.34371\n157/157 [==============================] - 108s 691ms/step - loss: 0.3448 - accuracy: 0.8127 - mean_io_u: 0.3809 - val_loss: 0.3450 - val_accuracy: 0.8157 - val_mean_io_u: 0.3780\nEpoch 25/50\n157/157 [==============================] - ETA: 0s - loss: 0.3409 - accuracy: 0.8162 - mean_io_u: 0.3796\nEpoch 25: val_loss did not improve from 0.34371\n157/157 [==============================] - 108s 690ms/step - loss: 0.3409 - accuracy: 0.8162 - mean_io_u: 0.3796 - val_loss: 0.3488 - val_accuracy: 0.8120 - val_mean_io_u: 0.3780\nEpoch 26/50\n157/157 [==============================] - ETA: 0s - loss: 0.3403 - accuracy: 0.8172 - mean_io_u: 0.3805\nEpoch 26: val_loss improved from 0.34371 to 0.33996, saving model to camus_best_model.h5\n157/157 [==============================] - 108s 691ms/step - loss: 0.3403 - accuracy: 0.8172 - mean_io_u: 0.3805 - val_loss: 0.3400 - val_accuracy: 0.8212 - val_mean_io_u: 0.3780\nEpoch 27/50\n157/157 [==============================] - ETA: 0s - loss: 0.3382 - accuracy: 0.8194 - mean_io_u: 0.3809\nEpoch 27: val_loss improved from 0.33996 to 0.33811, saving model to camus_best_model.h5\n157/157 [==============================] - 108s 691ms/step - loss: 0.3382 - accuracy: 0.8194 - mean_io_u: 0.3809 - val_loss: 0.3381 - val_accuracy: 0.8219 - val_mean_io_u: 0.3780\nEpoch 28/50\n157/157 [==============================] - ETA: 0s - loss: 0.3390 - accuracy: 0.8193 - mean_io_u: 0.3805\nEpoch 28: val_loss did not improve from 0.33811\n157/157 [==============================] - 108s 690ms/step - loss: 0.3390 - accuracy: 0.8193 - mean_io_u: 0.3805 - val_loss: 0.3426 - val_accuracy: 0.8177 - val_mean_io_u: 0.3780\nEpoch 29/50\n157/157 [==============================] - ETA: 0s - loss: 0.3364 - accuracy: 0.8205 - mean_io_u: 0.3797\nEpoch 29: val_loss improved from 0.33811 to 0.33710, saving model to camus_best_model.h5\n157/157 [==============================] - 108s 690ms/step - loss: 0.3364 - accuracy: 0.8205 - mean_io_u: 0.3797 - val_loss: 0.3371 - val_accuracy: 0.8215 - val_mean_io_u: 0.3780\nEpoch 30/50\n157/157 [==============================] - ETA: 0s - loss: 0.3352 - accuracy: 0.8211 - mean_io_u: 0.3817\nEpoch 30: val_loss did not improve from 0.33710\n157/157 [==============================] - 108s 689ms/step - loss: 0.3352 - accuracy: 0.8211 - mean_io_u: 0.3817 - val_loss: 0.3386 - val_accuracy: 0.8216 - val_mean_io_u: 0.3780\nEpoch 31/50\n157/157 [==============================] - ETA: 0s - loss: 0.3327 - accuracy: 0.8241 - mean_io_u: 0.3798\nEpoch 31: val_loss improved from 0.33710 to 0.33628, saving model to camus_best_model.h5\n157/157 [==============================] - 108s 691ms/step - loss: 0.3327 - accuracy: 0.8241 - mean_io_u: 0.3798 - val_loss: 0.3363 - val_accuracy: 0.8251 - val_mean_io_u: 0.3780\nEpoch 32/50\n157/157 [==============================] - ETA: 0s - loss: 0.3312 - accuracy: 0.8236 - mean_io_u: 0.3812\nEpoch 32: val_loss improved from 0.33628 to 0.33214, saving model to camus_best_model.h5\n157/157 [==============================] - 108s 689ms/step - loss: 0.3312 - accuracy: 0.8236 - mean_io_u: 0.3812 - val_loss: 0.3321 - val_accuracy: 0.8276 - val_mean_io_u: 0.3780\nEpoch 33/50\n157/157 [==============================] - ETA: 0s - loss: 0.3298 - accuracy: 0.8251 - mean_io_u: 0.3806\nEpoch 33: val_loss did not improve from 0.33214\n157/157 [==============================] - 109s 692ms/step - loss: 0.3298 - accuracy: 0.8251 - mean_io_u: 0.3806 - val_loss: 0.3355 - val_accuracy: 0.8235 - val_mean_io_u: 0.3780\nEpoch 34/50\n157/157 [==============================] - ETA: 0s - loss: 0.3347 - accuracy: 0.8234 - mean_io_u: 0.3788\nEpoch 34: val_loss did not improve from 0.33214\n157/157 [==============================] - 109s 693ms/step - loss: 0.3347 - accuracy: 0.8234 - mean_io_u: 0.3788 - val_loss: 0.3334 - val_accuracy: 0.8263 - val_mean_io_u: 0.3780\nEpoch 35/50\n157/157 [==============================] - ETA: 0s - loss: 0.3293 - accuracy: 0.8265 - mean_io_u: 0.3809\nEpoch 35: val_loss improved from 0.33214 to 0.33055, saving model to camus_best_model.h5\n157/157 [==============================] - 108s 690ms/step - loss: 0.3293 - accuracy: 0.8265 - mean_io_u: 0.3809 - val_loss: 0.3306 - val_accuracy: 0.8296 - val_mean_io_u: 0.3780\nEpoch 36/50\n157/157 [==============================] - ETA: 0s - loss: 0.3264 - accuracy: 0.8283 - mean_io_u: 0.3808\nEpoch 36: val_loss improved from 0.33055 to 0.32857, saving model to camus_best_model.h5\n157/157 [==============================] - 109s 693ms/step - loss: 0.3264 - accuracy: 0.8283 - mean_io_u: 0.3808 - val_loss: 0.3286 - val_accuracy: 0.8308 - val_mean_io_u: 0.3780\nEpoch 37/50\n157/157 [==============================] - ETA: 0s - loss: 0.3322 - accuracy: 0.8258 - mean_io_u: 0.3805\nEpoch 37: val_loss did not improve from 0.32857\n157/157 [==============================] - 109s 695ms/step - loss: 0.3322 - accuracy: 0.8258 - mean_io_u: 0.3805 - val_loss: 0.3345 - val_accuracy: 0.8232 - val_mean_io_u: 0.3780\nEpoch 38/50\n157/157 [==============================] - ETA: 0s - loss: 0.3296 - accuracy: 0.8275 - mean_io_u: 0.3798\nEpoch 38: val_loss did not improve from 0.32857\n157/157 [==============================] - 109s 692ms/step - loss: 0.3296 - accuracy: 0.8275 - mean_io_u: 0.3798 - val_loss: 0.3298 - val_accuracy: 0.8286 - val_mean_io_u: 0.3780\nEpoch 39/50\n157/157 [==============================] - ETA: 0s - loss: 0.3208 - accuracy: 0.8324 - mean_io_u: 0.3816\nEpoch 39: val_loss improved from 0.32857 to 0.32533, saving model to camus_best_model.h5\n157/157 [==============================] - 109s 694ms/step - loss: 0.3208 - accuracy: 0.8324 - mean_io_u: 0.3816 - val_loss: 0.3253 - val_accuracy: 0.8324 - val_mean_io_u: 0.3780\nEpoch 40/50\n157/157 [==============================] - ETA: 0s - loss: 0.3247 - accuracy: 0.8303 - mean_io_u: 0.3796\nEpoch 40: val_loss improved from 0.32533 to 0.32345, saving model to camus_best_model.h5\n157/157 [==============================] - 109s 693ms/step - loss: 0.3247 - accuracy: 0.8303 - mean_io_u: 0.3796 - val_loss: 0.3235 - val_accuracy: 0.8340 - val_mean_io_u: 0.3780\nEpoch 41/50\n157/157 [==============================] - ETA: 0s - loss: 0.3229 - accuracy: 0.8303 - mean_io_u: 0.3814\nEpoch 41: val_loss did not improve from 0.32345\n157/157 [==============================] - 109s 692ms/step - loss: 0.3229 - accuracy: 0.8303 - mean_io_u: 0.3814 - val_loss: 0.3254 - val_accuracy: 0.8302 - val_mean_io_u: 0.3780\nEpoch 42/50\n157/157 [==============================] - ETA: 0s - loss: 0.3223 - accuracy: 0.8321 - mean_io_u: 0.3795\nEpoch 42: val_loss improved from 0.32345 to 0.32219, saving model to camus_best_model.h5\n157/157 [==============================] - 108s 690ms/step - loss: 0.3223 - accuracy: 0.8321 - mean_io_u: 0.3795 - val_loss: 0.3222 - val_accuracy: 0.8344 - val_mean_io_u: 0.3780\nEpoch 43/50\n157/157 [==============================] - ETA: 0s - loss: 0.3216 - accuracy: 0.8322 - mean_io_u: 0.3810\nEpoch 43: val_loss did not improve from 0.32219\n157/157 [==============================] - 109s 692ms/step - loss: 0.3216 - accuracy: 0.8322 - mean_io_u: 0.3810 - val_loss: 0.3228 - val_accuracy: 0.8352 - val_mean_io_u: 0.3780\nEpoch 44/50\n157/157 [==============================] - ETA: 0s - loss: 0.3212 - accuracy: 0.8333 - mean_io_u: 0.3799\nEpoch 44: val_loss improved from 0.32219 to 0.31980, saving model to camus_best_model.h5\n157/157 [==============================] - 109s 694ms/step - loss: 0.3212 - accuracy: 0.8333 - mean_io_u: 0.3799 - val_loss: 0.3198 - val_accuracy: 0.8373 - val_mean_io_u: 0.3780\nEpoch 45/50\n157/157 [==============================] - ETA: 0s - loss: 0.3195 - accuracy: 0.8331 - mean_io_u: 0.3807\nEpoch 45: val_loss did not improve from 0.31980\n157/157 [==============================] - 108s 691ms/step - loss: 0.3195 - accuracy: 0.8331 - mean_io_u: 0.3807 - val_loss: 0.3288 - val_accuracy: 0.8292 - val_mean_io_u: 0.3780\nEpoch 46/50\n157/157 [==============================] - ETA: 0s - loss: 0.3217 - accuracy: 0.8330 - mean_io_u: 0.3800\nEpoch 46: val_loss did not improve from 0.31980\n157/157 [==============================] - 108s 689ms/step - loss: 0.3217 - accuracy: 0.8330 - mean_io_u: 0.3800 - val_loss: 0.3217 - val_accuracy: 0.8362 - val_mean_io_u: 0.3780\nEpoch 47/50\n157/157 [==============================] - ETA: 0s - loss: 0.3190 - accuracy: 0.8344 - mean_io_u: 0.3799\nEpoch 47: val_loss did not improve from 0.31980\n157/157 [==============================] - 108s 689ms/step - loss: 0.3190 - accuracy: 0.8344 - mean_io_u: 0.3799 - val_loss: 0.3232 - val_accuracy: 0.8348 - val_mean_io_u: 0.3780\nEpoch 48/50\n157/157 [==============================] - ETA: 0s - loss: 0.3161 - accuracy: 0.8368 - mean_io_u: 0.3797\nEpoch 48: val_loss did not improve from 0.31980\n157/157 [==============================] - 108s 689ms/step - loss: 0.3161 - accuracy: 0.8368 - mean_io_u: 0.3797 - val_loss: 0.3202 - val_accuracy: 0.8364 - val_mean_io_u: 0.3780\nEpoch 49/50\n157/157 [==============================] - ETA: 0s - loss: 0.3219 - accuracy: 0.8334 - mean_io_u: 0.3805\nEpoch 49: val_loss did not improve from 0.31980\n157/157 [==============================] - 108s 689ms/step - loss: 0.3219 - accuracy: 0.8334 - mean_io_u: 0.3805 - val_loss: 0.3230 - val_accuracy: 0.8359 - val_mean_io_u: 0.3780\nEpoch 50/50\n157/157 [==============================] - ETA: 0s - loss: 0.3146 - accuracy: 0.8372 - mean_io_u: 0.3803\nEpoch 50: val_loss did not improve from 0.31980\n157/157 [==============================] - 108s 689ms/step - loss: 0.3146 - accuracy: 0.8372 - mean_io_u: 0.3803 - val_loss: 0.3229 - val_accuracy: 0.8334 - val_mean_io_u: 0.3780\n34/34 [==============================] - 14s 414ms/step - loss: 0.3180 - accuracy: 0.8330 - mean_io_u: 0.3815\nTest Loss: 0.31801819801330566, Test Accuracy: 0.8330201506614685, Test IoU: 0.38154295086860657\nTraining completed and model saved!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"**Note:** In this notebook, I did replication of https://github.com/albergcg/camus_challenge and I tried something different that I was curious about. I trained model step by step without data leakage.","metadata":{}},{"cell_type":"markdown","source":"If you encounter with any error, you can find the dataset from following links:\n\nready-to-use version of camus: https://www.kaggle.com/datasets/toygarr/camus-dataset<br/>\nsubject-based splitted version of camus: https://www.kaggle.com/datasets/toygarr/camus-subject-based<br/>\noriginal dataset: https://humanheart-project.creatis.insa-lyon.fr/database/#collection/6373703d73e9f0047faa1bc8","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nimport h5py\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom tensorflow.keras.layers import (Conv2D, MaxPooling2D, Flatten, Dense, Dropout, \n                                   Conv2DTranspose, concatenate, Input, LSTM, Reshape)\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.metrics import MeanIoU\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\n\n# Set random seed for reproducibility\nnp.random.seed(42)\ntf.random.set_seed(42)\n\n# 1. Data Loading and Preparation\ndef load_camus_data(hdf5_path):\n    with h5py.File(hdf5_path, 'r') as f:\n        # Load 2CH and 4CH views\n        train_2ch_frames = np.array(f['train 2ch frames'])\n        train_2ch_masks = np.array(f['train 2ch masks'])\n        train_4ch_frames = np.array(f['train 4ch frames'])\n        train_4ch_masks = np.array(f['train 4ch masks'])\n        \n        # Create labels (0 for 2CH, 1 for 4CH)\n        train_2ch_labels = np.zeros(len(train_2ch_frames))\n        train_4ch_labels = np.ones(len(train_4ch_frames))\n        \n        # Combine all frames, masks and labels\n        all_frames = np.concatenate([train_2ch_frames, train_4ch_frames], axis=0)\n        all_masks = np.concatenate([train_2ch_masks, train_4ch_masks], axis=0)\n        all_labels = np.concatenate([train_2ch_labels, train_4ch_labels], axis=0)\n        \n        # Split into train (70%), val (15%), test (15%)\n        X_train, X_temp, y_train, y_temp, label_train, label_temp = train_test_split(\n            all_frames, all_masks, all_labels, test_size=0.3, random_state=42)\n        X_val, X_test, y_val, y_test, label_val, label_test = train_test_split(\n            X_temp, y_temp, label_temp, test_size=0.5, random_state=42)\n        \n    return (X_train, y_train, label_train), (X_val, y_val, label_val), (X_test, y_test, label_test)\n\n# Load the data\nhdf5_path = \"../input/camus-dataset/image_dataset.hdf5\"\n(X_train, y_train, label_train), (X_val, y_val, label_val), (X_test, y_test, label_test) = load_camus_data(hdf5_path)\n\n# Normalize images and convert masks to binary\nX_train = X_train.astype('float32') / 255.0\nX_val = X_val.astype('float32') / 255.0\nX_test = X_test.astype('float32') / 255.0\n\ny_train = (y_train > 0).astype('float32')\ny_val = (y_val > 0).astype('float32')\ny_test = (y_test > 0).astype('float32')\n\n# Convert labels to categorical\nlabel_train = to_categorical(label_train, num_classes=2)\nlabel_val = to_categorical(label_val, num_classes=2)\nlabel_test = to_categorical(label_test, num_classes=2)\n\n# 2. Data Generators\n# Corrected Data Generator Implementation\ndef create_generator(images, masks, labels=None, batch_size=8, augment=False):\n    if augment:\n        data_gen_args = dict(\n            rotation_range=10,\n            width_shift_range=0.1,\n            height_shift_range=0.1,\n            shear_range=0.1,\n            zoom_range=0.1,\n            horizontal_flip=True,\n            fill_mode='nearest')\n    else:\n        data_gen_args = dict()\n    \n    image_datagen = ImageDataGenerator(**data_gen_args)\n    mask_datagen = ImageDataGenerator(**data_gen_args)\n    \n    seed = 42\n    image_generator = image_datagen.flow(images, seed=seed, batch_size=batch_size)\n    mask_generator = mask_datagen.flow(masks, seed=seed, batch_size=batch_size)\n    \n    if labels is not None:\n        # Reshape labels to 4D (batch_size, 1, 1, num_classes) for ImageDataGenerator\n        labels_reshaped = labels.reshape(-1, 1, 1, labels.shape[1])\n        label_datagen = ImageDataGenerator(**data_gen_args)\n        label_generator = label_datagen.flow(labels_reshaped, seed=seed, batch_size=batch_size)\n        \n        while True:\n            # Get the next batch from each generator\n            x_batch = next(image_generator)\n            y_mask = next(mask_generator)\n            y_class = next(label_generator)\n            \n            # Squeeze the class labels back to 2D\n            y_class = y_class.reshape(-1, labels.shape[1])\n            \n            yield (x_batch, {'seg_output': y_mask, 'class_output': y_class})\n    else:\n        while True:\n            yield (next(image_generator), next(mask_generator))\n\n# Update the generators with the corrected implementation\nbatch_size = 8\ntrain_generator = create_generator(X_train, y_train, label_train, batch_size, augment=True)\nval_generator = create_generator(X_val, y_val, label_val, batch_size)\n      \n\n# 3. U-Net Model for Segmentation\ndef build_unet(input_shape):\n    inputs = Input(input_shape)\n    \n    # Downsample path\n    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n    \n    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    \n    # Bottleneck\n    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n    \n    # Upsample path\n    up4 = Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(conv3)\n    up4 = concatenate([up4, conv2])\n    conv4 = Conv2D(128, 3, activation='relu', padding='same')(up4)\n    conv4 = Conv2D(128, 3, activation='relu', padding='same')(conv4)\n    \n    up5 = Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv4)\n    up5 = concatenate([up5, conv1])\n    conv5 = Conv2D(64, 3, activation='relu', padding='same')(up5)\n    conv5 = Conv2D(64, 3, activation='relu', padding='same')(conv5)\n    \n    seg_output = Conv2D(1, 1, activation='sigmoid', name='seg_output')(conv5)\n    \n    # Classification branch\n    gap = tf.keras.layers.GlobalAveragePooling2D()(conv5)\n    class_output = Dense(2, activation='softmax', name='class_output')(gap)\n    \n    return Model(inputs=[inputs], outputs=[seg_output, class_output])\n\n# Build and compile multi-output model\nmodel = build_unet((384, 384, 1))\nmodel.compile(optimizer=Adam(learning_rate=1e-4),\n              loss={'seg_output': 'binary_crossentropy', 'class_output': 'categorical_crossentropy'},\n              metrics={'seg_output': ['accuracy', MeanIoU(num_classes=2)],\n                       'class_output': ['accuracy']})\n\n# Callbacks\ncallbacks = [\n    EarlyStopping(patience=10, verbose=1),\n    ModelCheckpoint('camus_best_model.h5', verbose=1, save_best_only=True)\n]\n\n# Train the model\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=len(X_train) // batch_size,\n    epochs=50,\n    validation_data=val_generator,\n    validation_steps=len(X_val) // batch_size,\n    callbacks=callbacks)\n\n# Save models\nmodel.save('camus_segmentation_classification_model.h5')\nprint(\"Segmentation and classification model saved\")\n\n# 4. RNN Model for Clinical Decision\ndef prepare_rnn_input(seg_results, class_results):\n    # Extract features from segmentation results\n    seg_features = np.array([np.mean(seg_results, axis=(1, 2, 3))]).T  # Mean activation\n    \n    # Combine with classification probabilities\n    features = np.concatenate([seg_features, class_results], axis=1)\n    \n    # Reshape for RNN (samples, timesteps, features)\n    return np.reshape(features, (features.shape[0], 1, features.shape[1]))\n\n# Generate synthetic labels for demonstration (0 = normal, 1 = abnormal)\n# In practice, you should use real clinical labels\nrnn_labels = np.random.randint(0, 2, size=(len(X_train),))\nrnn_labels = to_categorical(rnn_labels, num_classes=2)\n\n# Prepare RNN training data\nseg_pred, class_pred = model.predict(X_train, batch_size=batch_size)\nrnn_input = prepare_rnn_input(seg_pred, class_pred)\n\ndef create_rnn_model(input_shape):\n    model = Sequential([\n        LSTM(64, input_shape=input_shape),\n        Dense(32, activation='relu'),\n        Dense(2, activation='softmax')\n    ])\n    model.compile(loss='categorical_crossentropy',\n                 optimizer=Adam(learning_rate=1e-3),\n                 metrics=['accuracy'])\n    return model\n\nrnn_model = create_rnn_model((1, 3))  # 1 timestep, 3 features (seg feature + 2 class probs)\n\n# Train RNN\nrnn_history = rnn_model.fit(\n    rnn_input, \n    rnn_labels,\n    batch_size=32,\n    epochs=20,\n    validation_split=0.2)\n\n# Save RNN model\nrnn_model.save('camus_rnn_model.h5')\nprint(\"RNN model saved\")\n\n# 5. Clinical Report Generation\ndef generate_clinical_report(image):\n    # Expand dimensions if single image\n    if len(image.shape) == 3:\n        image = np.expand_dims(image, axis=0)\n    \n    # Get model predictions\n    seg_pred, class_pred = model.predict(image)\n    \n    # Prepare RNN input\n    rnn_input = prepare_rnn_input(seg_pred, class_pred)\n    \n    # Get clinical decision\n    rnn_pred = rnn_model.predict(rnn_input)\n    decision = np.argmax(rnn_pred, axis=1)[0]\n    \n    # Generate report\n    chamber_type = \"2-chamber\" if np.argmax(class_pred[0]) == 0 else \"4-chamber\"\n    severity = np.mean(seg_pred)\n    \n    report = f\"Echocardiogram Analysis Report:\\n\"\n    report += f\"View: {chamber_type}\\n\"\n    report += f\"Segmentation coverage: {severity:.2f}\\n\"\n    \n    if decision == 0:\n        report += \"Conclusion: NORMAL - No significant abnormalities detected.\"\n    else:\n        if severity < 0.3:\n            report += \"Conclusion: MILD ABNORMALITY - Recommend follow-up.\"\n        elif severity < 0.6:\n            report += \"Conclusion: MODERATE ABNORMALITY - Recommend cardiology consultation.\"\n        else:\n            report += \"Conclusion: SEVERE ABNORMALITY - Urgent intervention required.\"\n    \n    return report\n\n# Example usage\nsample_report = generate_clinical_report(X_test[0])\nprint(\"\\n\" + \"=\"*50)\nprint(sample_report)\nprint(\"=\"*50)\n\n# 6. Evaluation\ndef evaluate_models():\n    # Evaluate segmentation and classification\n    seg_pred, class_pred = model.predict(X_test, batch_size=batch_size)\n    seg_accuracy = np.mean((seg_pred > 0.5) == y_test)\n    class_accuracy = np.mean(np.argmax(class_pred, axis=1) == np.argmax(label_test, axis=1))\n    \n    print(f\"\\nSegmentation Accuracy: {seg_accuracy:.4f}\")\n    print(f\"Classification Accuracy: {class_accuracy:.4f}\")\n    \n    # Evaluate RNN (with synthetic labels)\n    rnn_test_input = prepare_rnn_input(seg_pred, class_pred)\n    rnn_test_labels = to_categorical(np.random.randint(0, 2, size=(len(X_test),)), num_classes=2)\n    rnn_loss, rnn_acc = rnn_model.evaluate(rnn_test_input, rnn_test_labels)\n    print(f\"RNN Accuracy: {rnn_acc:.4f}\")\n\nevaluate_models()","metadata":{"execution":{"iopub.status.busy":"2025-04-17T10:17:35.583223Z","iopub.execute_input":"2025-04-17T10:17:35.583566Z","iopub.status.idle":"2025-04-17T11:48:01.950435Z","shell.execute_reply.started":"2025-04-17T10:17:35.583543Z","shell.execute_reply":"2025-04-17T11:48:01.949581Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/preprocessing/image.py:766: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (1260, 1, 1, 2) (2 channels).\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n157/157 [==============================] - ETA: 0s - loss: 1.2748 - seg_output_loss: 0.5789 - class_output_loss: 0.6959 - seg_output_accuracy: 0.7536 - seg_output_mean_io_u_1: 0.3801 - class_output_accuracy: 0.4873","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/preprocessing/image.py:766: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (270, 1, 1, 2) (2 channels).\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_loss improved from inf to 1.21859, saving model to camus_best_model.h5\n157/157 [==============================] - 129s 678ms/step - loss: 1.2748 - seg_output_loss: 0.5789 - class_output_loss: 0.6959 - seg_output_accuracy: 0.7536 - seg_output_mean_io_u_1: 0.3801 - class_output_accuracy: 0.4873 - val_loss: 1.2186 - val_seg_output_loss: 0.5253 - val_class_output_loss: 0.6933 - val_seg_output_accuracy: 0.7558 - val_seg_output_mean_io_u_1: 0.3779 - val_class_output_accuracy: 0.4773\nEpoch 2/50\n157/157 [==============================] - ETA: 0s - loss: 1.1132 - seg_output_loss: 0.4153 - class_output_loss: 0.6980 - seg_output_accuracy: 0.7537 - seg_output_mean_io_u_1: 0.3801 - class_output_accuracy: 0.4936\nEpoch 2: val_loss improved from 1.21859 to 1.14692, saving model to camus_best_model.h5\n157/157 [==============================] - 114s 679ms/step - loss: 1.1132 - seg_output_loss: 0.4153 - class_output_loss: 0.6980 - seg_output_accuracy: 0.7537 - seg_output_mean_io_u_1: 0.3801 - class_output_accuracy: 0.4936 - val_loss: 1.1469 - val_seg_output_loss: 0.4360 - val_class_output_loss: 0.7109 - val_seg_output_accuracy: 0.7573 - val_seg_output_mean_io_u_1: 0.3786 - val_class_output_accuracy: 0.4773\nEpoch 3/50\n157/157 [==============================] - ETA: 0s - loss: 1.0810 - seg_output_loss: 0.3850 - class_output_loss: 0.6960 - seg_output_accuracy: 0.7713 - seg_output_mean_io_u_1: 0.3807 - class_output_accuracy: 0.4968\nEpoch 3: val_loss improved from 1.14692 to 1.09095, saving model to camus_best_model.h5\n157/157 [==============================] - 107s 679ms/step - loss: 1.0810 - seg_output_loss: 0.3850 - class_output_loss: 0.6960 - seg_output_accuracy: 0.7713 - seg_output_mean_io_u_1: 0.3807 - class_output_accuracy: 0.4968 - val_loss: 1.0909 - val_seg_output_loss: 0.3988 - val_class_output_loss: 0.6921 - val_seg_output_accuracy: 0.7623 - val_seg_output_mean_io_u_1: 0.3780 - val_class_output_accuracy: 0.5227\nEpoch 4/50\n157/157 [==============================] - ETA: 0s - loss: 1.0805 - seg_output_loss: 0.3851 - class_output_loss: 0.6954 - seg_output_accuracy: 0.7754 - seg_output_mean_io_u_1: 0.3807 - class_output_accuracy: 0.4832\nEpoch 4: val_loss improved from 1.09095 to 1.07237, saving model to camus_best_model.h5\n157/157 [==============================] - 107s 679ms/step - loss: 1.0805 - seg_output_loss: 0.3851 - class_output_loss: 0.6954 - seg_output_accuracy: 0.7754 - seg_output_mean_io_u_1: 0.3807 - class_output_accuracy: 0.4832 - val_loss: 1.0724 - val_seg_output_loss: 0.3791 - val_class_output_loss: 0.6933 - val_seg_output_accuracy: 0.7834 - val_seg_output_mean_io_u_1: 0.3777 - val_class_output_accuracy: 0.4735\nEpoch 5/50\n157/157 [==============================] - ETA: 0s - loss: 1.0770 - seg_output_loss: 0.3809 - class_output_loss: 0.6960 - seg_output_accuracy: 0.7782 - seg_output_mean_io_u_1: 0.3796 - class_output_accuracy: 0.4808\nEpoch 5: val_loss improved from 1.07237 to 1.06908, saving model to camus_best_model.h5\n157/157 [==============================] - 107s 680ms/step - loss: 1.0770 - seg_output_loss: 0.3809 - class_output_loss: 0.6960 - seg_output_accuracy: 0.7782 - seg_output_mean_io_u_1: 0.3796 - class_output_accuracy: 0.4808 - val_loss: 1.0691 - val_seg_output_loss: 0.3770 - val_class_output_loss: 0.6921 - val_seg_output_accuracy: 0.7783 - val_seg_output_mean_io_u_1: 0.3776 - val_class_output_accuracy: 0.5227\nEpoch 6/50\n157/157 [==============================] - ETA: 0s - loss: 1.0734 - seg_output_loss: 0.3787 - class_output_loss: 0.6947 - seg_output_accuracy: 0.7848 - seg_output_mean_io_u_1: 0.3798 - class_output_accuracy: 0.5200\nEpoch 6: val_loss did not improve from 1.06908\n157/157 [==============================] - 106s 677ms/step - loss: 1.0734 - seg_output_loss: 0.3787 - class_output_loss: 0.6947 - seg_output_accuracy: 0.7848 - seg_output_mean_io_u_1: 0.3798 - class_output_accuracy: 0.5200 - val_loss: 1.0726 - val_seg_output_loss: 0.3762 - val_class_output_loss: 0.6964 - val_seg_output_accuracy: 0.7883 - val_seg_output_mean_io_u_1: 0.3779 - val_class_output_accuracy: 0.4811\nEpoch 7/50\n157/157 [==============================] - ETA: 0s - loss: 1.0681 - seg_output_loss: 0.3728 - class_output_loss: 0.6953 - seg_output_accuracy: 0.7881 - seg_output_mean_io_u_1: 0.3797 - class_output_accuracy: 0.4856\nEpoch 7: val_loss improved from 1.06908 to 1.05727, saving model to camus_best_model.h5\n157/157 [==============================] - 106s 678ms/step - loss: 1.0681 - seg_output_loss: 0.3728 - class_output_loss: 0.6953 - seg_output_accuracy: 0.7881 - seg_output_mean_io_u_1: 0.3797 - class_output_accuracy: 0.4856 - val_loss: 1.0573 - val_seg_output_loss: 0.3654 - val_class_output_loss: 0.6919 - val_seg_output_accuracy: 0.7938 - val_seg_output_mean_io_u_1: 0.3781 - val_class_output_accuracy: 0.5265\nEpoch 8/50\n157/157 [==============================] - ETA: 0s - loss: 1.0625 - seg_output_loss: 0.3679 - class_output_loss: 0.6946 - seg_output_accuracy: 0.7900 - seg_output_mean_io_u_1: 0.3806 - class_output_accuracy: 0.4968\nEpoch 8: val_loss did not improve from 1.05727\n157/157 [==============================] - 106s 677ms/step - loss: 1.0625 - seg_output_loss: 0.3679 - class_output_loss: 0.6946 - seg_output_accuracy: 0.7900 - seg_output_mean_io_u_1: 0.3806 - class_output_accuracy: 0.4968 - val_loss: 1.0687 - val_seg_output_loss: 0.3762 - val_class_output_loss: 0.6925 - val_seg_output_accuracy: 0.7861 - val_seg_output_mean_io_u_1: 0.3784 - val_class_output_accuracy: 0.5189\nEpoch 9/50\n157/157 [==============================] - ETA: 0s - loss: 1.0597 - seg_output_loss: 0.3662 - class_output_loss: 0.6935 - seg_output_accuracy: 0.7931 - seg_output_mean_io_u_1: 0.3794 - class_output_accuracy: 0.5256\nEpoch 9: val_loss improved from 1.05727 to 1.05516, saving model to camus_best_model.h5\n157/157 [==============================] - 107s 679ms/step - loss: 1.0597 - seg_output_loss: 0.3662 - class_output_loss: 0.6935 - seg_output_accuracy: 0.7931 - seg_output_mean_io_u_1: 0.3794 - class_output_accuracy: 0.5256 - val_loss: 1.0552 - val_seg_output_loss: 0.3628 - val_class_output_loss: 0.6924 - val_seg_output_accuracy: 0.7956 - val_seg_output_mean_io_u_1: 0.3785 - val_class_output_accuracy: 0.5189\nEpoch 10/50\n157/157 [==============================] - ETA: 0s - loss: 1.0600 - seg_output_loss: 0.3657 - class_output_loss: 0.6943 - seg_output_accuracy: 0.7936 - seg_output_mean_io_u_1: 0.3796 - class_output_accuracy: 0.4888\nEpoch 10: val_loss did not improve from 1.05516\n157/157 [==============================] - 107s 679ms/step - loss: 1.0600 - seg_output_loss: 0.3657 - class_output_loss: 0.6943 - seg_output_accuracy: 0.7936 - seg_output_mean_io_u_1: 0.3796 - class_output_accuracy: 0.4888 - val_loss: 1.0589 - val_seg_output_loss: 0.3622 - val_class_output_loss: 0.6967 - val_seg_output_accuracy: 0.7944 - val_seg_output_mean_io_u_1: 0.3785 - val_class_output_accuracy: 0.4811\nEpoch 11/50\n157/157 [==============================] - ETA: 0s - loss: 1.0581 - seg_output_loss: 0.3630 - class_output_loss: 0.6951 - seg_output_accuracy: 0.7956 - seg_output_mean_io_u_1: 0.3803 - class_output_accuracy: 0.4824\nEpoch 11: val_loss did not improve from 1.05516\n157/157 [==============================] - 107s 679ms/step - loss: 1.0581 - seg_output_loss: 0.3630 - class_output_loss: 0.6951 - seg_output_accuracy: 0.7956 - seg_output_mean_io_u_1: 0.3803 - class_output_accuracy: 0.4824 - val_loss: 1.0556 - val_seg_output_loss: 0.3632 - val_class_output_loss: 0.6924 - val_seg_output_accuracy: 0.7947 - val_seg_output_mean_io_u_1: 0.3783 - val_class_output_accuracy: 0.5152\nEpoch 12/50\n157/157 [==============================] - ETA: 0s - loss: 1.0584 - seg_output_loss: 0.3641 - class_output_loss: 0.6942 - seg_output_accuracy: 0.7962 - seg_output_mean_io_u_1: 0.3797 - class_output_accuracy: 0.5056\nEpoch 12: val_loss improved from 1.05516 to 1.05357, saving model to camus_best_model.h5\n157/157 [==============================] - 107s 683ms/step - loss: 1.0584 - seg_output_loss: 0.3641 - class_output_loss: 0.6942 - seg_output_accuracy: 0.7962 - seg_output_mean_io_u_1: 0.3797 - class_output_accuracy: 0.5056 - val_loss: 1.0536 - val_seg_output_loss: 0.3607 - val_class_output_loss: 0.6928 - val_seg_output_accuracy: 0.7992 - val_seg_output_mean_io_u_1: 0.3780 - val_class_output_accuracy: 0.5644\nEpoch 13/50\n157/157 [==============================] - ETA: 0s - loss: 1.0534 - seg_output_loss: 0.3589 - class_output_loss: 0.6945 - seg_output_accuracy: 0.7980 - seg_output_mean_io_u_1: 0.3798 - class_output_accuracy: 0.4888\nEpoch 13: val_loss improved from 1.05357 to 1.04781, saving model to camus_best_model.h5\n157/157 [==============================] - 107s 683ms/step - loss: 1.0534 - seg_output_loss: 0.3589 - class_output_loss: 0.6945 - seg_output_accuracy: 0.7980 - seg_output_mean_io_u_1: 0.3798 - class_output_accuracy: 0.4888 - val_loss: 1.0478 - val_seg_output_loss: 0.3571 - val_class_output_loss: 0.6907 - val_seg_output_accuracy: 0.8021 - val_seg_output_mean_io_u_1: 0.3784 - val_class_output_accuracy: 0.5303\nEpoch 14/50\n157/157 [==============================] - ETA: 0s - loss: 1.0520 - seg_output_loss: 0.3573 - class_output_loss: 0.6947 - seg_output_accuracy: 0.7992 - seg_output_mean_io_u_1: 0.3804 - class_output_accuracy: 0.5024\nEpoch 14: val_loss did not improve from 1.04781\n157/157 [==============================] - 107s 680ms/step - loss: 1.0520 - seg_output_loss: 0.3573 - class_output_loss: 0.6947 - seg_output_accuracy: 0.7992 - seg_output_mean_io_u_1: 0.3804 - class_output_accuracy: 0.5024 - val_loss: 1.0504 - val_seg_output_loss: 0.3584 - val_class_output_loss: 0.6920 - val_seg_output_accuracy: 0.8019 - val_seg_output_mean_io_u_1: 0.3778 - val_class_output_accuracy: 0.4924\nEpoch 15/50\n157/157 [==============================] - ETA: 0s - loss: 1.0540 - seg_output_loss: 0.3597 - class_output_loss: 0.6943 - seg_output_accuracy: 0.7973 - seg_output_mean_io_u_1: 0.3798 - class_output_accuracy: 0.4792\nEpoch 15: val_loss did not improve from 1.04781\n157/157 [==============================] - 107s 679ms/step - loss: 1.0540 - seg_output_loss: 0.3597 - class_output_loss: 0.6943 - seg_output_accuracy: 0.7973 - seg_output_mean_io_u_1: 0.3798 - class_output_accuracy: 0.4792 - val_loss: 1.0551 - val_seg_output_loss: 0.3636 - val_class_output_loss: 0.6916 - val_seg_output_accuracy: 0.7950 - val_seg_output_mean_io_u_1: 0.3786 - val_class_output_accuracy: 0.5227\nEpoch 16/50\n157/157 [==============================] - ETA: 0s - loss: 1.0501 - seg_output_loss: 0.3576 - class_output_loss: 0.6925 - seg_output_accuracy: 0.8009 - seg_output_mean_io_u_1: 0.3797 - class_output_accuracy: 0.5120\nEpoch 16: val_loss did not improve from 1.04781\n157/157 [==============================] - 107s 680ms/step - loss: 1.0501 - seg_output_loss: 0.3576 - class_output_loss: 0.6925 - seg_output_accuracy: 0.8009 - seg_output_mean_io_u_1: 0.3797 - class_output_accuracy: 0.5120 - val_loss: 1.0707 - val_seg_output_loss: 0.3587 - val_class_output_loss: 0.7120 - val_seg_output_accuracy: 0.7990 - val_seg_output_mean_io_u_1: 0.3789 - val_class_output_accuracy: 0.4773\nEpoch 17/50\n157/157 [==============================] - ETA: 0s - loss: 1.0511 - seg_output_loss: 0.3575 - class_output_loss: 0.6936 - seg_output_accuracy: 0.7997 - seg_output_mean_io_u_1: 0.3799 - class_output_accuracy: 0.5088\nEpoch 17: val_loss improved from 1.04781 to 1.04651, saving model to camus_best_model.h5\n157/157 [==============================] - 107s 681ms/step - loss: 1.0511 - seg_output_loss: 0.3575 - class_output_loss: 0.6936 - seg_output_accuracy: 0.7997 - seg_output_mean_io_u_1: 0.3799 - class_output_accuracy: 0.5088 - val_loss: 1.0465 - val_seg_output_loss: 0.3552 - val_class_output_loss: 0.6913 - val_seg_output_accuracy: 0.8041 - val_seg_output_mean_io_u_1: 0.3779 - val_class_output_accuracy: 0.5038\nEpoch 18/50\n157/157 [==============================] - ETA: 0s - loss: 1.0514 - seg_output_loss: 0.3581 - class_output_loss: 0.6933 - seg_output_accuracy: 0.8010 - seg_output_mean_io_u_1: 0.3790 - class_output_accuracy: 0.5184\nEpoch 18: val_loss improved from 1.04651 to 1.04329, saving model to camus_best_model.h5\n157/157 [==============================] - 107s 681ms/step - loss: 1.0514 - seg_output_loss: 0.3581 - class_output_loss: 0.6933 - seg_output_accuracy: 0.8010 - seg_output_mean_io_u_1: 0.3790 - class_output_accuracy: 0.5184 - val_loss: 1.0433 - val_seg_output_loss: 0.3525 - val_class_output_loss: 0.6908 - val_seg_output_accuracy: 0.8061 - val_seg_output_mean_io_u_1: 0.3782 - val_class_output_accuracy: 0.5189\nEpoch 19/50\n157/157 [==============================] - ETA: 0s - loss: 1.0459 - seg_output_loss: 0.3525 - class_output_loss: 0.6933 - seg_output_accuracy: 0.8030 - seg_output_mean_io_u_1: 0.3813 - class_output_accuracy: 0.5056\nEpoch 19: val_loss did not improve from 1.04329\n157/157 [==============================] - 107s 680ms/step - loss: 1.0459 - seg_output_loss: 0.3525 - class_output_loss: 0.6933 - seg_output_accuracy: 0.8030 - seg_output_mean_io_u_1: 0.3813 - class_output_accuracy: 0.5056 - val_loss: 1.0468 - val_seg_output_loss: 0.3565 - val_class_output_loss: 0.6902 - val_seg_output_accuracy: 0.8024 - val_seg_output_mean_io_u_1: 0.3784 - val_class_output_accuracy: 0.5227\nEpoch 20/50\n157/157 [==============================] - ETA: 0s - loss: 1.0472 - seg_output_loss: 0.3541 - class_output_loss: 0.6932 - seg_output_accuracy: 0.8032 - seg_output_mean_io_u_1: 0.3800 - class_output_accuracy: 0.5112\nEpoch 20: val_loss did not improve from 1.04329\n157/157 [==============================] - 107s 680ms/step - loss: 1.0472 - seg_output_loss: 0.3541 - class_output_loss: 0.6932 - seg_output_accuracy: 0.8032 - seg_output_mean_io_u_1: 0.3800 - class_output_accuracy: 0.5112 - val_loss: 1.0470 - val_seg_output_loss: 0.3563 - val_class_output_loss: 0.6906 - val_seg_output_accuracy: 0.8072 - val_seg_output_mean_io_u_1: 0.3777 - val_class_output_accuracy: 0.5265\nEpoch 21/50\n157/157 [==============================] - ETA: 0s - loss: 1.0445 - seg_output_loss: 0.3505 - class_output_loss: 0.6941 - seg_output_accuracy: 0.8044 - seg_output_mean_io_u_1: 0.3804 - class_output_accuracy: 0.5056\nEpoch 21: val_loss improved from 1.04329 to 1.04121, saving model to camus_best_model.h5\n157/157 [==============================] - 107s 680ms/step - loss: 1.0445 - seg_output_loss: 0.3505 - class_output_loss: 0.6941 - seg_output_accuracy: 0.8044 - seg_output_mean_io_u_1: 0.3804 - class_output_accuracy: 0.5056 - val_loss: 1.0412 - val_seg_output_loss: 0.3514 - val_class_output_loss: 0.6898 - val_seg_output_accuracy: 0.8068 - val_seg_output_mean_io_u_1: 0.3779 - val_class_output_accuracy: 0.5114\nEpoch 22/50\n157/157 [==============================] - ETA: 0s - loss: 1.0467 - seg_output_loss: 0.3544 - class_output_loss: 0.6923 - seg_output_accuracy: 0.8031 - seg_output_mean_io_u_1: 0.3805 - class_output_accuracy: 0.5335\nEpoch 22: val_loss improved from 1.04121 to 1.04114, saving model to camus_best_model.h5\n157/157 [==============================] - 107s 679ms/step - loss: 1.0467 - seg_output_loss: 0.3544 - class_output_loss: 0.6923 - seg_output_accuracy: 0.8031 - seg_output_mean_io_u_1: 0.3805 - class_output_accuracy: 0.5335 - val_loss: 1.0411 - val_seg_output_loss: 0.3507 - val_class_output_loss: 0.6904 - val_seg_output_accuracy: 0.8073 - val_seg_output_mean_io_u_1: 0.3782 - val_class_output_accuracy: 0.5227\nEpoch 23/50\n157/157 [==============================] - ETA: 0s - loss: 1.0453 - seg_output_loss: 0.3530 - class_output_loss: 0.6923 - seg_output_accuracy: 0.8022 - seg_output_mean_io_u_1: 0.3800 - class_output_accuracy: 0.5184\nEpoch 23: val_loss improved from 1.04114 to 1.04025, saving model to camus_best_model.h5\n157/157 [==============================] - 107s 680ms/step - loss: 1.0453 - seg_output_loss: 0.3530 - class_output_loss: 0.6923 - seg_output_accuracy: 0.8022 - seg_output_mean_io_u_1: 0.3800 - class_output_accuracy: 0.5184 - val_loss: 1.0403 - val_seg_output_loss: 0.3512 - val_class_output_loss: 0.6891 - val_seg_output_accuracy: 0.8068 - val_seg_output_mean_io_u_1: 0.3777 - val_class_output_accuracy: 0.5114\nEpoch 24/50\n157/157 [==============================] - ETA: 0s - loss: 1.0447 - seg_output_loss: 0.3534 - class_output_loss: 0.6912 - seg_output_accuracy: 0.8041 - seg_output_mean_io_u_1: 0.3799 - class_output_accuracy: 0.5136\nEpoch 24: val_loss improved from 1.04025 to 1.03854, saving model to camus_best_model.h5\n157/157 [==============================] - 107s 680ms/step - loss: 1.0447 - seg_output_loss: 0.3534 - class_output_loss: 0.6912 - seg_output_accuracy: 0.8041 - seg_output_mean_io_u_1: 0.3799 - class_output_accuracy: 0.5136 - val_loss: 1.0385 - val_seg_output_loss: 0.3516 - val_class_output_loss: 0.6869 - val_seg_output_accuracy: 0.8076 - val_seg_output_mean_io_u_1: 0.3780 - val_class_output_accuracy: 0.5227\nEpoch 25/50\n157/157 [==============================] - ETA: 0s - loss: 1.0414 - seg_output_loss: 0.3518 - class_output_loss: 0.6896 - seg_output_accuracy: 0.8048 - seg_output_mean_io_u_1: 0.3802 - class_output_accuracy: 0.5423\nEpoch 25: val_loss did not improve from 1.03854\n157/157 [==============================] - 107s 681ms/step - loss: 1.0414 - seg_output_loss: 0.3518 - class_output_loss: 0.6896 - seg_output_accuracy: 0.8048 - seg_output_mean_io_u_1: 0.3802 - class_output_accuracy: 0.5423 - val_loss: 1.0388 - val_seg_output_loss: 0.3502 - val_class_output_loss: 0.6885 - val_seg_output_accuracy: 0.8101 - val_seg_output_mean_io_u_1: 0.3786 - val_class_output_accuracy: 0.5114\nEpoch 26/50\n157/157 [==============================] - ETA: 0s - loss: 1.0438 - seg_output_loss: 0.3534 - class_output_loss: 0.6903 - seg_output_accuracy: 0.8045 - seg_output_mean_io_u_1: 0.3789 - class_output_accuracy: 0.5224\nEpoch 26: val_loss improved from 1.03854 to 1.03630, saving model to camus_best_model.h5\n157/157 [==============================] - 107s 680ms/step - loss: 1.0438 - seg_output_loss: 0.3534 - class_output_loss: 0.6903 - seg_output_accuracy: 0.8045 - seg_output_mean_io_u_1: 0.3789 - class_output_accuracy: 0.5224 - val_loss: 1.0363 - val_seg_output_loss: 0.3481 - val_class_output_loss: 0.6882 - val_seg_output_accuracy: 0.8087 - val_seg_output_mean_io_u_1: 0.3782 - val_class_output_accuracy: 0.6098\nEpoch 27/50\n157/157 [==============================] - ETA: 0s - loss: 1.0394 - seg_output_loss: 0.3508 - class_output_loss: 0.6886 - seg_output_accuracy: 0.8049 - seg_output_mean_io_u_1: 0.3807 - class_output_accuracy: 0.5335\nEpoch 27: val_loss improved from 1.03630 to 1.03164, saving model to camus_best_model.h5\n157/157 [==============================] - 107s 680ms/step - loss: 1.0394 - seg_output_loss: 0.3508 - class_output_loss: 0.6886 - seg_output_accuracy: 0.8049 - seg_output_mean_io_u_1: 0.3807 - class_output_accuracy: 0.5335 - val_loss: 1.0316 - val_seg_output_loss: 0.3503 - val_class_output_loss: 0.6814 - val_seg_output_accuracy: 0.8111 - val_seg_output_mean_io_u_1: 0.3788 - val_class_output_accuracy: 0.6212\nEpoch 28/50\n157/157 [==============================] - ETA: 0s - loss: 1.0372 - seg_output_loss: 0.3492 - class_output_loss: 0.6879 - seg_output_accuracy: 0.8053 - seg_output_mean_io_u_1: 0.3810 - class_output_accuracy: 0.5407\nEpoch 28: val_loss did not improve from 1.03164\n157/157 [==============================] - 107s 679ms/step - loss: 1.0372 - seg_output_loss: 0.3492 - class_output_loss: 0.6879 - seg_output_accuracy: 0.8053 - seg_output_mean_io_u_1: 0.3810 - class_output_accuracy: 0.5407 - val_loss: 1.0385 - val_seg_output_loss: 0.3520 - val_class_output_loss: 0.6865 - val_seg_output_accuracy: 0.8103 - val_seg_output_mean_io_u_1: 0.3782 - val_class_output_accuracy: 0.4886\nEpoch 29/50\n157/157 [==============================] - ETA: 0s - loss: 1.0348 - seg_output_loss: 0.3558 - class_output_loss: 0.6790 - seg_output_accuracy: 0.8045 - seg_output_mean_io_u_1: 0.3790 - class_output_accuracy: 0.5623\nEpoch 29: val_loss improved from 1.03164 to 1.02769, saving model to camus_best_model.h5\n157/157 [==============================] - 106s 678ms/step - loss: 1.0348 - seg_output_loss: 0.3558 - class_output_loss: 0.6790 - seg_output_accuracy: 0.8045 - seg_output_mean_io_u_1: 0.3790 - class_output_accuracy: 0.5623 - val_loss: 1.0277 - val_seg_output_loss: 0.3597 - val_class_output_loss: 0.6680 - val_seg_output_accuracy: 0.8009 - val_seg_output_mean_io_u_1: 0.3788 - val_class_output_accuracy: 0.6742\nEpoch 30/50\n157/157 [==============================] - ETA: 0s - loss: 1.0284 - seg_output_loss: 0.3534 - class_output_loss: 0.6749 - seg_output_accuracy: 0.8037 - seg_output_mean_io_u_1: 0.3804 - class_output_accuracy: 0.5903\nEpoch 30: val_loss did not improve from 1.02769\n157/157 [==============================] - 106s 677ms/step - loss: 1.0284 - seg_output_loss: 0.3534 - class_output_loss: 0.6749 - seg_output_accuracy: 0.8037 - seg_output_mean_io_u_1: 0.3804 - class_output_accuracy: 0.5903 - val_loss: 1.0287 - val_seg_output_loss: 0.3567 - val_class_output_loss: 0.6720 - val_seg_output_accuracy: 0.8062 - val_seg_output_mean_io_u_1: 0.3780 - val_class_output_accuracy: 0.5682\nEpoch 31/50\n157/157 [==============================] - ETA: 0s - loss: 1.0256 - seg_output_loss: 0.3603 - class_output_loss: 0.6653 - seg_output_accuracy: 0.8022 - seg_output_mean_io_u_1: 0.3806 - class_output_accuracy: 0.5958\nEpoch 31: val_loss did not improve from 1.02769\n157/157 [==============================] - 106s 677ms/step - loss: 1.0256 - seg_output_loss: 0.3603 - class_output_loss: 0.6653 - seg_output_accuracy: 0.8022 - seg_output_mean_io_u_1: 0.3806 - class_output_accuracy: 0.5958 - val_loss: 1.1328 - val_seg_output_loss: 0.3857 - val_class_output_loss: 0.7471 - val_seg_output_accuracy: 0.7747 - val_seg_output_mean_io_u_1: 0.3782 - val_class_output_accuracy: 0.4886\nEpoch 32/50\n157/157 [==============================] - ETA: 0s - loss: 1.0150 - seg_output_loss: 0.3547 - class_output_loss: 0.6604 - seg_output_accuracy: 0.8042 - seg_output_mean_io_u_1: 0.3797 - class_output_accuracy: 0.6118\nEpoch 32: val_loss did not improve from 1.02769\n157/157 [==============================] - 106s 677ms/step - loss: 1.0150 - seg_output_loss: 0.3547 - class_output_loss: 0.6604 - seg_output_accuracy: 0.8042 - seg_output_mean_io_u_1: 0.3797 - class_output_accuracy: 0.6118 - val_loss: 1.0661 - val_seg_output_loss: 0.3746 - val_class_output_loss: 0.6915 - val_seg_output_accuracy: 0.7911 - val_seg_output_mean_io_u_1: 0.3784 - val_class_output_accuracy: 0.5606\nEpoch 33/50\n157/157 [==============================] - ETA: 0s - loss: 1.0040 - seg_output_loss: 0.3546 - class_output_loss: 0.6494 - seg_output_accuracy: 0.8062 - seg_output_mean_io_u_1: 0.3806 - class_output_accuracy: 0.6070\nEpoch 33: val_loss improved from 1.02769 to 0.94068, saving model to camus_best_model.h5\n157/157 [==============================] - 107s 681ms/step - loss: 1.0040 - seg_output_loss: 0.3546 - class_output_loss: 0.6494 - seg_output_accuracy: 0.8062 - seg_output_mean_io_u_1: 0.3806 - class_output_accuracy: 0.6070 - val_loss: 0.9407 - val_seg_output_loss: 0.3468 - val_class_output_loss: 0.5939 - val_seg_output_accuracy: 0.8093 - val_seg_output_mean_io_u_1: 0.3785 - val_class_output_accuracy: 0.7614\nEpoch 34/50\n157/157 [==============================] - ETA: 0s - loss: 0.9988 - seg_output_loss: 0.3553 - class_output_loss: 0.6434 - seg_output_accuracy: 0.8058 - seg_output_mean_io_u_1: 0.3799 - class_output_accuracy: 0.6326\nEpoch 34: val_loss did not improve from 0.94068\n157/157 [==============================] - 106s 679ms/step - loss: 0.9988 - seg_output_loss: 0.3553 - class_output_loss: 0.6434 - seg_output_accuracy: 0.8058 - seg_output_mean_io_u_1: 0.3799 - class_output_accuracy: 0.6326 - val_loss: 1.1265 - val_seg_output_loss: 0.4246 - val_class_output_loss: 0.7020 - val_seg_output_accuracy: 0.7741 - val_seg_output_mean_io_u_1: 0.3780 - val_class_output_accuracy: 0.5795\nEpoch 35/50\n157/157 [==============================] - ETA: 0s - loss: 0.9790 - seg_output_loss: 0.3542 - class_output_loss: 0.6248 - seg_output_accuracy: 0.8071 - seg_output_mean_io_u_1: 0.3799 - class_output_accuracy: 0.6534\nEpoch 35: val_loss improved from 0.94068 to 0.92494, saving model to camus_best_model.h5\n157/157 [==============================] - 106s 678ms/step - loss: 0.9790 - seg_output_loss: 0.3542 - class_output_loss: 0.6248 - seg_output_accuracy: 0.8071 - seg_output_mean_io_u_1: 0.3799 - class_output_accuracy: 0.6534 - val_loss: 0.9249 - val_seg_output_loss: 0.3483 - val_class_output_loss: 0.5767 - val_seg_output_accuracy: 0.8091 - val_seg_output_mean_io_u_1: 0.3788 - val_class_output_accuracy: 0.7576\nEpoch 36/50\n157/157 [==============================] - ETA: 0s - loss: 0.9562 - seg_output_loss: 0.3488 - class_output_loss: 0.6073 - seg_output_accuracy: 0.8087 - seg_output_mean_io_u_1: 0.3801 - class_output_accuracy: 0.6853\nEpoch 36: val_loss did not improve from 0.92494\n157/157 [==============================] - 106s 678ms/step - loss: 0.9562 - seg_output_loss: 0.3488 - class_output_loss: 0.6073 - seg_output_accuracy: 0.8087 - seg_output_mean_io_u_1: 0.3801 - class_output_accuracy: 0.6853 - val_loss: 0.9293 - val_seg_output_loss: 0.3733 - val_class_output_loss: 0.5560 - val_seg_output_accuracy: 0.7993 - val_seg_output_mean_io_u_1: 0.3783 - val_class_output_accuracy: 0.7614\nEpoch 37/50\n157/157 [==============================] - ETA: 0s - loss: 0.9496 - seg_output_loss: 0.3517 - class_output_loss: 0.5979 - seg_output_accuracy: 0.8077 - seg_output_mean_io_u_1: 0.3799 - class_output_accuracy: 0.6877\nEpoch 37: val_loss improved from 0.92494 to 0.88882, saving model to camus_best_model.h5\n157/157 [==============================] - 107s 679ms/step - loss: 0.9496 - seg_output_loss: 0.3517 - class_output_loss: 0.5979 - seg_output_accuracy: 0.8077 - seg_output_mean_io_u_1: 0.3799 - class_output_accuracy: 0.6877 - val_loss: 0.8888 - val_seg_output_loss: 0.3477 - val_class_output_loss: 0.5411 - val_seg_output_accuracy: 0.8121 - val_seg_output_mean_io_u_1: 0.3781 - val_class_output_accuracy: 0.7652\nEpoch 38/50\n157/157 [==============================] - ETA: 0s - loss: 0.9314 - seg_output_loss: 0.3538 - class_output_loss: 0.5776 - seg_output_accuracy: 0.8066 - seg_output_mean_io_u_1: 0.3796 - class_output_accuracy: 0.7061\nEpoch 38: val_loss did not improve from 0.88882\n157/157 [==============================] - 106s 678ms/step - loss: 0.9314 - seg_output_loss: 0.3538 - class_output_loss: 0.5776 - seg_output_accuracy: 0.8066 - seg_output_mean_io_u_1: 0.3796 - class_output_accuracy: 0.7061 - val_loss: 0.9096 - val_seg_output_loss: 0.3518 - val_class_output_loss: 0.5577 - val_seg_output_accuracy: 0.8096 - val_seg_output_mean_io_u_1: 0.3795 - val_class_output_accuracy: 0.7311\nEpoch 39/50\n157/157 [==============================] - ETA: 0s - loss: 0.9024 - seg_output_loss: 0.3495 - class_output_loss: 0.5529 - seg_output_accuracy: 0.8074 - seg_output_mean_io_u_1: 0.3820 - class_output_accuracy: 0.7372\nEpoch 39: val_loss improved from 0.88882 to 0.85721, saving model to camus_best_model.h5\n157/157 [==============================] - 106s 678ms/step - loss: 0.9024 - seg_output_loss: 0.3495 - class_output_loss: 0.5529 - seg_output_accuracy: 0.8074 - seg_output_mean_io_u_1: 0.3820 - class_output_accuracy: 0.7372 - val_loss: 0.8572 - val_seg_output_loss: 0.3513 - val_class_output_loss: 0.5059 - val_seg_output_accuracy: 0.8121 - val_seg_output_mean_io_u_1: 0.3780 - val_class_output_accuracy: 0.7841\nEpoch 40/50\n157/157 [==============================] - ETA: 0s - loss: 0.8944 - seg_output_loss: 0.3502 - class_output_loss: 0.5443 - seg_output_accuracy: 0.8058 - seg_output_mean_io_u_1: 0.3798 - class_output_accuracy: 0.7157\nEpoch 40: val_loss did not improve from 0.85721\n157/157 [==============================] - 106s 678ms/step - loss: 0.8944 - seg_output_loss: 0.3502 - class_output_loss: 0.5443 - seg_output_accuracy: 0.8058 - seg_output_mean_io_u_1: 0.3798 - class_output_accuracy: 0.7157 - val_loss: 0.8948 - val_seg_output_loss: 0.3535 - val_class_output_loss: 0.5413 - val_seg_output_accuracy: 0.8028 - val_seg_output_mean_io_u_1: 0.3787 - val_class_output_accuracy: 0.7652\nEpoch 41/50\n157/157 [==============================] - ETA: 0s - loss: 0.8805 - seg_output_loss: 0.3503 - class_output_loss: 0.5302 - seg_output_accuracy: 0.8071 - seg_output_mean_io_u_1: 0.3799 - class_output_accuracy: 0.7508\nEpoch 41: val_loss did not improve from 0.85721\n157/157 [==============================] - 106s 676ms/step - loss: 0.8805 - seg_output_loss: 0.3503 - class_output_loss: 0.5302 - seg_output_accuracy: 0.8071 - seg_output_mean_io_u_1: 0.3799 - class_output_accuracy: 0.7508 - val_loss: 0.8708 - val_seg_output_loss: 0.3560 - val_class_output_loss: 0.5148 - val_seg_output_accuracy: 0.8112 - val_seg_output_mean_io_u_1: 0.3785 - val_class_output_accuracy: 0.7614\nEpoch 42/50\n157/157 [==============================] - ETA: 0s - loss: 0.8621 - seg_output_loss: 0.3575 - class_output_loss: 0.5047 - seg_output_accuracy: 0.8031 - seg_output_mean_io_u_1: 0.3795 - class_output_accuracy: 0.7588\nEpoch 42: val_loss did not improve from 0.85721\n157/157 [==============================] - 106s 676ms/step - loss: 0.8621 - seg_output_loss: 0.3575 - class_output_loss: 0.5047 - seg_output_accuracy: 0.8031 - seg_output_mean_io_u_1: 0.3795 - class_output_accuracy: 0.7588 - val_loss: 0.9097 - val_seg_output_loss: 0.3513 - val_class_output_loss: 0.5584 - val_seg_output_accuracy: 0.8124 - val_seg_output_mean_io_u_1: 0.3783 - val_class_output_accuracy: 0.7159\nEpoch 43/50\n157/157 [==============================] - ETA: 0s - loss: 0.8383 - seg_output_loss: 0.3470 - class_output_loss: 0.4913 - seg_output_accuracy: 0.8090 - seg_output_mean_io_u_1: 0.3804 - class_output_accuracy: 0.7716\nEpoch 43: val_loss did not improve from 0.85721\n157/157 [==============================] - 106s 676ms/step - loss: 0.8383 - seg_output_loss: 0.3470 - class_output_loss: 0.4913 - seg_output_accuracy: 0.8090 - seg_output_mean_io_u_1: 0.3804 - class_output_accuracy: 0.7716 - val_loss: 0.9317 - val_seg_output_loss: 0.3497 - val_class_output_loss: 0.5819 - val_seg_output_accuracy: 0.8099 - val_seg_output_mean_io_u_1: 0.3783 - val_class_output_accuracy: 0.6780\nEpoch 44/50\n157/157 [==============================] - ETA: 0s - loss: 0.8208 - seg_output_loss: 0.3470 - class_output_loss: 0.4738 - seg_output_accuracy: 0.8097 - seg_output_mean_io_u_1: 0.3807 - class_output_accuracy: 0.7764\nEpoch 44: val_loss did not improve from 0.85721\n157/157 [==============================] - 106s 676ms/step - loss: 0.8208 - seg_output_loss: 0.3470 - class_output_loss: 0.4738 - seg_output_accuracy: 0.8097 - seg_output_mean_io_u_1: 0.3807 - class_output_accuracy: 0.7764 - val_loss: 1.0030 - val_seg_output_loss: 0.3568 - val_class_output_loss: 0.6462 - val_seg_output_accuracy: 0.8027 - val_seg_output_mean_io_u_1: 0.3787 - val_class_output_accuracy: 0.6364\nEpoch 45/50\n157/157 [==============================] - ETA: 0s - loss: 0.8456 - seg_output_loss: 0.3521 - class_output_loss: 0.4936 - seg_output_accuracy: 0.8071 - seg_output_mean_io_u_1: 0.3802 - class_output_accuracy: 0.7827\nEpoch 45: val_loss improved from 0.85721 to 0.80684, saving model to camus_best_model.h5\n157/157 [==============================] - 106s 677ms/step - loss: 0.8456 - seg_output_loss: 0.3521 - class_output_loss: 0.4936 - seg_output_accuracy: 0.8071 - seg_output_mean_io_u_1: 0.3802 - class_output_accuracy: 0.7827 - val_loss: 0.8068 - val_seg_output_loss: 0.3535 - val_class_output_loss: 0.4533 - val_seg_output_accuracy: 0.8133 - val_seg_output_mean_io_u_1: 0.3778 - val_class_output_accuracy: 0.7992\nEpoch 46/50\n157/157 [==============================] - ETA: 0s - loss: 0.7955 - seg_output_loss: 0.3496 - class_output_loss: 0.4459 - seg_output_accuracy: 0.8107 - seg_output_mean_io_u_1: 0.3792 - class_output_accuracy: 0.8003\nEpoch 46: val_loss improved from 0.80684 to 0.79711, saving model to camus_best_model.h5\n157/157 [==============================] - 106s 678ms/step - loss: 0.7955 - seg_output_loss: 0.3496 - class_output_loss: 0.4459 - seg_output_accuracy: 0.8107 - seg_output_mean_io_u_1: 0.3792 - class_output_accuracy: 0.8003 - val_loss: 0.7971 - val_seg_output_loss: 0.3539 - val_class_output_loss: 0.4432 - val_seg_output_accuracy: 0.8107 - val_seg_output_mean_io_u_1: 0.3780 - val_class_output_accuracy: 0.8106\nEpoch 47/50\n157/157 [==============================] - ETA: 0s - loss: 0.7638 - seg_output_loss: 0.3462 - class_output_loss: 0.4176 - seg_output_accuracy: 0.8106 - seg_output_mean_io_u_1: 0.3803 - class_output_accuracy: 0.8267\nEpoch 47: val_loss did not improve from 0.79711\n157/157 [==============================] - 106s 676ms/step - loss: 0.7638 - seg_output_loss: 0.3462 - class_output_loss: 0.4176 - seg_output_accuracy: 0.8106 - seg_output_mean_io_u_1: 0.3803 - class_output_accuracy: 0.8267 - val_loss: 0.7993 - val_seg_output_loss: 0.3449 - val_class_output_loss: 0.4545 - val_seg_output_accuracy: 0.8099 - val_seg_output_mean_io_u_1: 0.3784 - val_class_output_accuracy: 0.7841\nEpoch 48/50\n157/157 [==============================] - ETA: 0s - loss: 0.7840 - seg_output_loss: 0.3487 - class_output_loss: 0.4352 - seg_output_accuracy: 0.8099 - seg_output_mean_io_u_1: 0.3797 - class_output_accuracy: 0.7963\nEpoch 48: val_loss improved from 0.79711 to 0.77962, saving model to camus_best_model.h5\n157/157 [==============================] - 106s 677ms/step - loss: 0.7840 - seg_output_loss: 0.3487 - class_output_loss: 0.4352 - seg_output_accuracy: 0.8099 - seg_output_mean_io_u_1: 0.3797 - class_output_accuracy: 0.7963 - val_loss: 0.7796 - val_seg_output_loss: 0.3476 - val_class_output_loss: 0.4320 - val_seg_output_accuracy: 0.8138 - val_seg_output_mean_io_u_1: 0.3787 - val_class_output_accuracy: 0.7992\nEpoch 49/50\n157/157 [==============================] - ETA: 0s - loss: 0.7805 - seg_output_loss: 0.3479 - class_output_loss: 0.4325 - seg_output_accuracy: 0.8117 - seg_output_mean_io_u_1: 0.3798 - class_output_accuracy: 0.8011\nEpoch 49: val_loss did not improve from 0.77962\n157/157 [==============================] - 106s 676ms/step - loss: 0.7805 - seg_output_loss: 0.3479 - class_output_loss: 0.4325 - seg_output_accuracy: 0.8117 - seg_output_mean_io_u_1: 0.3798 - class_output_accuracy: 0.8011 - val_loss: 0.8168 - val_seg_output_loss: 0.3521 - val_class_output_loss: 0.4647 - val_seg_output_accuracy: 0.8157 - val_seg_output_mean_io_u_1: 0.3780 - val_class_output_accuracy: 0.7841\nEpoch 50/50\n157/157 [==============================] - ETA: 0s - loss: 0.7690 - seg_output_loss: 0.3553 - class_output_loss: 0.4137 - seg_output_accuracy: 0.8081 - seg_output_mean_io_u_1: 0.3806 - class_output_accuracy: 0.8107\nEpoch 50: val_loss did not improve from 0.77962\n157/157 [==============================] - 106s 678ms/step - loss: 0.7690 - seg_output_loss: 0.3553 - class_output_loss: 0.4137 - seg_output_accuracy: 0.8081 - seg_output_mean_io_u_1: 0.3806 - class_output_accuracy: 0.8107 - val_loss: 0.8417 - val_seg_output_loss: 0.3631 - val_class_output_loss: 0.4786 - val_seg_output_accuracy: 0.8040 - val_seg_output_mean_io_u_1: 0.3780 - val_class_output_accuracy: 0.7727\nSegmentation and classification model saved\n158/158 [==============================] - 31s 193ms/step\nEpoch 1/20\n32/32 [==============================] - 3s 17ms/step - loss: 0.6938 - accuracy: 0.5040 - val_loss: 0.6954 - val_accuracy: 0.4325\nEpoch 2/20\n32/32 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.4782 - val_loss: 0.6932 - val_accuracy: 0.4960\nEpoch 3/20\n32/32 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.4990 - val_loss: 0.6948 - val_accuracy: 0.4325\nEpoch 4/20\n32/32 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.4960 - val_loss: 0.6944 - val_accuracy: 0.4325\nEpoch 5/20\n32/32 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5040 - val_loss: 0.6944 - val_accuracy: 0.4325\nEpoch 6/20\n32/32 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5060 - val_loss: 0.6938 - val_accuracy: 0.4365\nEpoch 7/20\n32/32 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5040 - val_loss: 0.6944 - val_accuracy: 0.4325\nEpoch 8/20\n32/32 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5040 - val_loss: 0.6932 - val_accuracy: 0.4722\nEpoch 9/20\n32/32 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.4990 - val_loss: 0.6940 - val_accuracy: 0.4325\nEpoch 10/20\n32/32 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.4702 - val_loss: 0.6939 - val_accuracy: 0.4405\nEpoch 11/20\n32/32 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.4692 - val_loss: 0.6931 - val_accuracy: 0.4762\nEpoch 12/20\n32/32 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.4901 - val_loss: 0.6941 - val_accuracy: 0.4563\nEpoch 13/20\n32/32 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5060 - val_loss: 0.6949 - val_accuracy: 0.4325\nEpoch 14/20\n32/32 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.4891 - val_loss: 0.6924 - val_accuracy: 0.5317\nEpoch 15/20\n32/32 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5030 - val_loss: 0.6947 - val_accuracy: 0.4325\nEpoch 16/20\n32/32 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5099 - val_loss: 0.6938 - val_accuracy: 0.4444\nEpoch 17/20\n32/32 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.4980 - val_loss: 0.6931 - val_accuracy: 0.4683\nEpoch 18/20\n32/32 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.4921 - val_loss: 0.6938 - val_accuracy: 0.4444\nEpoch 19/20\n32/32 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6940 - val_accuracy: 0.4683\nEpoch 20/20\n32/32 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.4722\nRNN model saved\n1/1 [==============================] - 2s 2s/step\n1/1 [==============================] - 0s 314ms/step\n\n==================================================\nEchocardiogram Analysis Report:\nView: 4-chamber\nSegmentation coverage: 0.30\nConclusion: MILD ABNORMALITY - Recommend follow-up.\n==================================================\n34/34 [==============================] - 13s 392ms/step\n\nSegmentation Accuracy: 0.8043\nClassification Accuracy: 0.8222\n9/9 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5000\nRNN Accuracy: 0.5000\n","output_type":"stream"}],"execution_count":2}]}